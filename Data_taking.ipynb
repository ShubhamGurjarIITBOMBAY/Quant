{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBIN1KnNc57s"
      },
      "outputs": [],
      "source": [
        "# Import statements\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import math\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSTYudmmXNlg"
      },
      "source": [
        "Get the options price data from [1]. \\\\\n",
        "Alternatively, we have uploaded the data to Google Drive, and it can be downloaded from there [2]. \\\\\n",
        "We do not need the full dataset, only the NIFTY and BANKNIFTY Call Options with Traded Value>1000 lakhs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "NLDGYwcLXwTq",
        "outputId": "2b7f7c31-1306-4c1f-8f1e-094e8f7801da"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '3mfanddo.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a58f3fa39b61>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter out the required data from the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3mfanddo.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Create a CSV reader object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m  \u001b[0;31m# Define the header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '3mfanddo.csv'"
          ]
        }
      ],
      "source": [
        "# Filter out the required data from the csv file\n",
        "with open('3mfanddo.csv', 'r') as file:\n",
        "    reader = csv.DictReader(file)   # Create a CSV reader object\n",
        "    header = reader.fieldnames  # Define the header\n",
        "\n",
        "    # Create an empty list to store filtered rows\n",
        "    filtered_rows = []\n",
        "\n",
        "    # Iterate over each row in the CSV file\n",
        "    for row in reader:\n",
        "        # Check if the 'INSTRUMENT' column has values 'OPTIDX'\n",
        "        if (row['INSTRUMENT']=='OPTIDX') and (float(row['VAL_INLAKH'])>=1000) and (row['OPTION_TYP']=='CE'):\n",
        "          filtered_rows.append(row)\n",
        "data = pd.DataFrame(filtered_rows)\n",
        "del filtered_rows   # To save RAM\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "\n",
        "# Find the range of dates in the dataframe\n",
        "temp = pd.to_datetime(data['TIMESTAMP'], format='%d-%b-%Y')\n",
        "min_date = temp.min()\n",
        "max_date = temp.max()\n",
        "print(\"Minimum date:\", min_date)\n",
        "print(\"Maximum date:\", max_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-IcVagfe5Tq"
      },
      "outputs": [],
      "source": [
        "# Remove the unnecessary columns and datapints\n",
        "data = data.dropna(inplace=True)\n",
        "data.drop(['', 'INSTRUMENT', 'OPTION_TYP', 'CLOSE', 'TIMESTAMP'], inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MZikiLhf3BG"
      },
      "outputs": [],
      "source": [
        "# Get the underlying banknifty/nifty close data using yfinance api [4] [5]\n",
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr\n",
        "yf.pdr_override()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxowuy0agc6P"
      },
      "outputs": [],
      "source": [
        "# Get the underlying close price\n",
        "# %%capture\n",
        "import math\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "eta = 0\n",
        "eta_count = 1\n",
        "eta_time = 0\n",
        "N = data.shape[0]\n",
        "\n",
        "data['UNDER_CLOSE'] = 0   # Price of the underlying symbol\n",
        "\n",
        "symbols_not_available = []\n",
        "drop_indices = []\n",
        "for index in range(N):\n",
        "  row = data.loc[index]\n",
        "\n",
        "  # To get the estimated time to completion\n",
        "  if(eta_count == 1000 ):\n",
        "    eta_count = 1\n",
        "    eta = (time.time() - eta_time) * (N-index)/ 1000\n",
        "    eta_time = time.time()\n",
        "    print(\"ETA in seconds:\", eta)\n",
        "    print(index, '/', N)\n",
        "  eta_count += 1\n",
        "\n",
        "  # To check if under_close already exists\n",
        "  if math.isnan(row['UNDER_CLOSE']) == False and row['UNDER_CLOSE']!=0:\n",
        "    print(row)\n",
        "    continue\n",
        "\n",
        "  symbol = row['SYMBOL']\n",
        "  date_str = row['TIMESTAMP']\n",
        "  parsed_date = datetime.strptime(date_str, '%d-%b-%Y')\n",
        "  next_date = parsed_date + timedelta(days=1)\n",
        "\n",
        "  # These symbols have been delisted/discontinued\n",
        "  if(symbol in symbols_not_available):\n",
        "    data.drop(index=index, inplace=True)\n",
        "    continue\n",
        "\n",
        "  if(symbol=='NIFTY'):\n",
        "    yf_symbol = '^NSEI'\n",
        "  elif(symbol=='BANKNIFTY'):\n",
        "    yf_symbol ='^NSEBANK'\n",
        "  elif(symbol=='NIFTYIT'):\n",
        "    yf_symbol = '^CNXIT'\n",
        "  else:\n",
        "    yf_symbol = symbol+\".NS\"\n",
        "\n",
        "  try:\n",
        "    close_data = yf.download(yf_symbol, start = parsed_date.strftime('%Y-%m-%d'), end = next_date.strftime('%Y-%m-%d'), progress=False)\n",
        "  except:\n",
        "    symbols_not_available.append(symbol)\n",
        "    drop_indices.append(index)\n",
        "    continue\n",
        "  try:\n",
        "    data.at[index, 'UNDER_CLOSE'] = close_data['Close'].values[0]\n",
        "  except:\n",
        "    symbols_not_available.append(symbol)\n",
        "    drop_indices.append(index)\n",
        "    continue\n",
        "\n",
        "data.drop(drop_indices, axis=0, inplace=True)\n",
        "print(data.columns)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK-_VJIHhNZK"
      },
      "outputs": [],
      "source": [
        "# Get the risk-free returns using the Government 10-Year Treasury Bill returns from [6]\n",
        "# The csv file has been uploaded to drive at [3]\n",
        "risk_data_path = 'India 10-Year Bond Yield Historical Data.csv'\n",
        "risk_data = pd.read_csv(risk_data_path)\n",
        "risk_data['Date'] = pd.to_datetime(risk_data['Date'], format='%d-%m-%Y')\n",
        "print(risk_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEsXuWF5iDq7"
      },
      "outputs": [],
      "source": [
        "# Append the risk free interest rate to the dataframe\n",
        "# Append the (expiry - date) (days to expiry) as a column in the dataframe, with time in years\n",
        "# A year is taken as 252 days, excluding weekend holidays\n",
        "\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "N = data.shape[0]\n",
        "drop_rows = []\n",
        "data['risk_free_rate'] = 0\n",
        "for index in range(N):\n",
        "  row = data.loc[index]\n",
        "  date_str = row['TIMESTAMP']\n",
        "  parsed_date = datetime.strptime(date_str, '%d-%b-%Y')\n",
        "  expiry_str = row['EXPIRY_DT']\n",
        "  parsed_expiry = datetime.strptime(expiry_str, '%d-%b-%Y')\n",
        "  delta_days =parsed_expiry - parsed_date\n",
        "  data.at[index,'to_expiry'] = delta_days/252\n",
        "\n",
        "  temp_date = risk_data[risk_data['Date'] == parsed_date]\n",
        "  if len(temp_date) == 0:\n",
        "    drop_rows.append(index)\n",
        "    continue\n",
        "  risk_free_rate = temp_date['Price'].values[0]\n",
        "\n",
        "  data.at[index,'risk_free_rate'] = risk_free_rate\n",
        "\n",
        "data.drop(drop_rows, axis=0, inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data['to_expiry'] = data['to_expiry'].dt.days\n",
        "data.drop(['EXPIRY_DT'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "japcTd8Iir-b"
      },
      "outputs": [],
      "source": [
        "# Calculate the volatilites (times 100), which is the annualised standard deviation\n",
        "\n",
        "# Sort data according to TIMESTAMP column\n",
        "data['TIMESTAMP'] = pd.to_datetime(data['TIMESTAMP'], format='%d-%b-%Y')\n",
        "data = data.sort_values(by='TIMESTAMP')\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "def update_history(history, price):\n",
        "  if len(history) <= 10:\n",
        "    history.append(price)\n",
        "    return history\n",
        "  for i in range(len(history)-1):\n",
        "    history[i] = history[i+1]\n",
        "  history[-1] = price\n",
        "  return history\n",
        "\n",
        "def get_annual_volatility(stock_prices):\n",
        "  log_returns = [np.log(stock_prices[i] / stock_prices[i-1]) for i in range(1, len(stock_prices))]\n",
        "  std_dev = np.std(log_returns)\n",
        "  annualized_std_dev = std_dev * np.sqrt(252)\n",
        "  return annualized_std_dev\n",
        "\n",
        "# Get volatility\n",
        "banknifty_volatilites = {}  # To store the dates for which vol has been calculated\n",
        "nifty_volatilites = {}\n",
        "\n",
        "banknifty_window = []   # TO get the rolling window to calculate vol\n",
        "nifty_window = []\n",
        "\n",
        "data['VOLATILITY'] = 0    # Initialise the column\n",
        "\n",
        "for index in range(len(data)):\n",
        "  row = data.loc[index]\n",
        "  if row['SYMBOL'] == 'BANKNIFTY':\n",
        "    if row['TIMESTAMP'] not in banknifty_volatilites:\n",
        "      if len(banknifty_window) < 20:\n",
        "        banknifty_window.append(row['UNDER_CLOSE'])\n",
        "        banknifty_volatilites[row['TIMESTAMP']] = 0\n",
        "      else:\n",
        "        banknifty_window = update_history(banknifty_window, row['UNDER_CLOSE'])\n",
        "        banknifty_volatilites[row['TIMESTAMP']] = get_annual_volatility(banknifty_window)\n",
        "    data.at[index, 'VOLATILITY'] = banknifty_volatilites[row['TIMESTAMP']]\n",
        "  else:\n",
        "    if row['TIMESTAMP'] not in nifty_volatilites:\n",
        "      if len(nifty_window) < 20:\n",
        "        nifty_window.append(row['UNDER_CLOSE'])\n",
        "        nifty_volatilites[row['TIMESTAMP']] = 0\n",
        "      else:\n",
        "        nifty_window = update_history(nifty_window, row['UNDER_CLOSE'])\n",
        "        nifty_volatilites[row['TIMESTAMP']] = get_annual_volatility(nifty_window)\n",
        "    data.at[index, 'VOLATILITY'] = nifty_volatilites[row['TIMESTAMP']]\n",
        "\n",
        "data['VOLATILITY'] = data['VOLATILITY'] * 100\n",
        "data = data[data['VOLATILITY'] != 0]    # Remove thosewith zero volatility\n",
        "\n",
        "# Store the final dataset as a csv file for future purposes\n",
        "data.to_csv('data_final.csv', index=False)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awg1BVk-oBjg"
      },
      "outputs": [],
      "source": [
        "# Get banknifty and nifty data for training the LSTM\n",
        "banknifty_data = yf.download('^NSEBANK', start=\"2014-11-30\", end=\"2019-11-30\")\n",
        "nifty_data = yf.download('^NSEI', start=\"2014-11-30\", end=\"2019-11-30\")\n",
        "\n",
        "banknifty_data = banknifty_data[ 'Close']\n",
        "nifty_data = nifty_data[ 'Close']\n",
        "\n",
        "banknifty_data.to_csv('banknifty_data.csv')\n",
        "nifty_data.to_csv('nifty_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc4kduJWXZ9i"
      },
      "source": [
        "# *References*:\n",
        "[1] https://www.kaggle.com/datasets/sunnysai12345/nse-future-and-options-dataset-3m\n",
        "[2]https://drive.google.com/file/d/1LEfYIu2TYorRgzpMXc70FxslUtrkzg9G/view?usp=sharing   \n",
        "[3] https://drive.google.com/file/d/17eWAPg10eQ3iEXcrbWtUwm0z8UFKhInj/view?usp=sharing  \n",
        "[4] https://pypi.org/project/yfinance/    \n",
        "[5] https://medium.com/@dhruvi31/initializing-yfinance-to-get-nse-stock-price-data-2d05b9c920f2     \n",
        "[6] https://in.investing.com/rates-bonds/india-10-year-bond-yield-historical-data\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
